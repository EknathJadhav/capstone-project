{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GDBFYFVdYsXV",
        "outputId": "570498a5-7091-4106-c043-041d0b15abae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the dataset:\n",
            "   Sl No  Sample ID  Age  Gender  inter canine distance intraoral  \\\n",
            "0      1        NaN   24  Female                            25.06   \n",
            "1      2        NaN   22  Female                            25.78   \n",
            "2      3        NaN   23  Female                            23.83   \n",
            "3      4        NaN   20  Female                            26.12   \n",
            "4      5        NaN   20  Female                            26.36   \n",
            "\n",
            "   intercanine distance casts  right canine width intraoral  \\\n",
            "0                       25.05                          6.08   \n",
            "1                       25.79                          6.13   \n",
            "2                       23.83                          5.91   \n",
            "3                       26.12                          6.08   \n",
            "4                       26.41                          6.09   \n",
            "\n",
            "   right canine width casts  left canine width intraoral  \\\n",
            "0                      6.08                         6.09   \n",
            "1                      6.13                         6.33   \n",
            "2                      5.96                         6.28   \n",
            "3                      6.08                         6.56   \n",
            "4                      6.09                         6.50   \n",
            "\n",
            "   left canine width casts  right canine index intra oral  \\\n",
            "0                     6.10                          0.242   \n",
            "1                     6.33                          0.237   \n",
            "2                     6.28                          0.248   \n",
            "3                     6.56                          0.232   \n",
            "4                     6.50                          0.231   \n",
            "\n",
            "   right canine index casts  left canine index intraoral  \\\n",
            "0                     0.242                        0.242   \n",
            "1                     0.237                        0.247   \n",
            "2                     0.248                        0.264   \n",
            "3                     0.232                        0.250   \n",
            "4                     0.231                        0.246   \n",
            "\n",
            "   left canine index casts  \n",
            "0                    0.241  \n",
            "1                    0.247  \n",
            "2                    0.264  \n",
            "3                    0.250  \n",
            "4                    0.246  \n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1100 entries, 0 to 1099\n",
            "Data columns (total 14 columns):\n",
            " #   Column                           Non-Null Count  Dtype  \n",
            "---  ------                           --------------  -----  \n",
            " 0   Sl No                            1100 non-null   int64  \n",
            " 1   Sample ID                        0 non-null      float64\n",
            " 2   Age                              1100 non-null   int64  \n",
            " 3   Gender                           1100 non-null   object \n",
            " 4   inter canine distance intraoral  1100 non-null   float64\n",
            " 5   intercanine distance casts       1100 non-null   float64\n",
            " 6   right canine width intraoral     1100 non-null   float64\n",
            " 7   right canine width casts         1100 non-null   float64\n",
            " 8   left canine width intraoral      1100 non-null   float64\n",
            " 9   left canine width casts          1100 non-null   float64\n",
            " 10  right canine index intra oral    1100 non-null   float64\n",
            " 11  right canine index casts         1100 non-null   float64\n",
            " 12  left canine index intraoral      1100 non-null   float64\n",
            " 13  left canine index casts          1100 non-null   float64\n",
            "dtypes: float64(11), int64(2), object(1)\n",
            "memory usage: 120.4+ KB\n",
            "None\n",
            "\n",
            "Summary Statistics:\n",
            "             Sl No  Sample ID          Age  inter canine distance intraoral  \\\n",
            "count  1100.000000        0.0  1100.000000                      1100.000000   \n",
            "mean    550.500000        NaN    21.625455                        25.989009   \n",
            "std     317.686953        NaN     2.085892                         1.315292   \n",
            "min       1.000000        NaN    18.000000                        23.120000   \n",
            "25%     275.750000        NaN    20.000000                        25.000000   \n",
            "50%     550.500000        NaN    22.000000                        25.900000   \n",
            "75%     825.250000        NaN    23.000000                        26.992500   \n",
            "max    1100.000000        NaN    25.000000                        30.310000   \n",
            "\n",
            "       intercanine distance casts  right canine width intraoral  \\\n",
            "count                 1100.000000                   1100.000000   \n",
            "mean                    25.880082                      6.563000   \n",
            "std                      1.862323                      0.379035   \n",
            "min                      6.540000                      5.460000   \n",
            "25%                     24.980000                      6.290000   \n",
            "50%                     25.900000                      6.520000   \n",
            "75%                     27.000000                      6.802500   \n",
            "max                     30.310000                      7.610000   \n",
            "\n",
            "       right canine width casts  left canine width intraoral  \\\n",
            "count               1100.000000                  1100.000000   \n",
            "mean                   6.564491                     6.669627   \n",
            "std                    0.377553                     0.375841   \n",
            "min                    5.460000                     5.460000   \n",
            "25%                    6.300000                     6.400000   \n",
            "50%                    6.520000                     6.660000   \n",
            "75%                    6.802500                     6.910000   \n",
            "max                    7.600000                     7.810000   \n",
            "\n",
            "       left canine width casts  right canine index intra oral  \\\n",
            "count              1100.000000                    1100.000000   \n",
            "mean                  6.675018                       0.253122   \n",
            "std                   0.377098                       0.015344   \n",
            "min                   5.460000                       0.223000   \n",
            "25%                   6.407500                       0.242000   \n",
            "50%                   6.680000                       0.253000   \n",
            "75%                   6.920000                       0.262000   \n",
            "max                   7.810000                       0.363000   \n",
            "\n",
            "       right canine index casts  left canine index intraoral  \\\n",
            "count               1100.000000                  1100.000000   \n",
            "mean                   0.252355                     0.256453   \n",
            "std                    0.012892                     0.012355   \n",
            "min                    0.223000                     0.223000   \n",
            "25%                    0.242000                     0.247000   \n",
            "50%                    0.253000                     0.255000   \n",
            "75%                    0.261250                     0.264250   \n",
            "max                    0.302000                     0.305000   \n",
            "\n",
            "       left canine index casts  \n",
            "count              1100.000000  \n",
            "mean                  0.256361  \n",
            "std                   0.012374  \n",
            "min                   0.223000  \n",
            "25%                   0.247000  \n",
            "50%                   0.255000  \n",
            "75%                   0.264000  \n",
            "max                   0.304000  \n",
            "\n",
            "Checking for missing values:\n",
            "Sl No                                 0\n",
            "Sample ID                          1100\n",
            "Age                                   0\n",
            "Gender                                0\n",
            "inter canine distance intraoral       0\n",
            "intercanine distance casts            0\n",
            "right canine width intraoral          0\n",
            "right canine width casts              0\n",
            "left canine width intraoral           0\n",
            "left canine width casts               0\n",
            "right canine index intra oral         0\n",
            "right canine index casts              0\n",
            "left canine index intraoral           0\n",
            "left canine index casts               0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-41b504302420>:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data[column].fillna(data[column].mean(), inplace=True)\n",
            "<ipython-input-1-41b504302420>:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data[column].fillna(data[column].mode()[0], inplace=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input X contains NaN.\nNormalizer does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-41b504302420>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Normalize Features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mnormalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Step 6: Exploratory Data Analysis (EDA)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m         \"\"\"\n\u001b[0;32m-> 2082\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2083\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1065\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             )\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nNormalizer does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, Normalizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Step 1: Load Dataset\n",
        "file_path = '/content/Dentistry Dataset.csv'  # Update this path to the actual file location\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Data Inspection\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(data.head())\n",
        "print(\"\\nDataset Info:\")\n",
        "print(data.info())\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(data.describe())\n",
        "\n",
        "# Step 3: Handle Missing Values\n",
        "print(\"\\nChecking for missing values:\")\n",
        "print(data.isnull().sum())\n",
        "# Replace missing values with mean/mode as appropriate\n",
        "for column in data.columns:\n",
        "    if data[column].dtype == 'object':\n",
        "        data[column].fillna(data[column].mode()[0], inplace=True)\n",
        "    else:\n",
        "        data[column].fillna(data[column].mean(), inplace=True)\n",
        "\n",
        "# Step 4: Encode Categorical Data\n",
        "label_encoder = LabelEncoder()\n",
        "data['Gender'] = label_encoder.fit_transform(data['Gender'])  # Encode target variable\n",
        "\n",
        "# Step 5: Split Independent (X) and Dependent Variables (Y)\n",
        "X = data.drop(columns=['Gender', 'SampleID', 'SL No.'], errors='ignore')  # Drop non-feature columns\n",
        "y = data['Gender']\n",
        "\n",
        "# Normalize Features\n",
        "normalizer = Normalizer()\n",
        "X_normalized = normalizer.fit_transform(X)\n",
        "\n",
        "# Step 6: Exploratory Data Analysis (EDA)\n",
        "# Heatmap to visualize correlation\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(pd.DataFrame(X_normalized, columns=X.columns).corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Feature Correlation Heatmap')\n",
        "plt.show()\n",
        "\n",
        "# Step 7: Split Data into Train and Test Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 8: Model Building and Evaluation\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluation Metrics\n",
        "    print(f\"Results for {name}:\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # ROC-AUC Curve\n",
        "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'r--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve - {name}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, Normalizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.impute import SimpleImputer  # Import SimpleImputer\n",
        "\n",
        "# Step 1: Load Dataset\n",
        "file_path = '/content/Dentistry Dataset.csv'  # Update this path to the actual file location\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# ... (rest of your code up to Step 4) ...\n",
        "\n",
        "# Step 5: Split Independent (X) and Dependent Variables (Y)\n",
        "X = data.drop(columns=['Gender', 'SampleID', 'SL No.'], errors='ignore')  # Drop non-feature columns\n",
        "y = data['Gender']\n",
        "\n",
        "# Impute missing values using SimpleImputer before normalization\n",
        "imputer = SimpleImputer(strategy='mean') # Create an imputer instance\n",
        "X = imputer.fit_transform(X) # Impute missing values in X\n",
        "\n",
        "# Normalize Features\n",
        "normalizer = Normalizer()\n",
        "X_normalized = normalizer.fit_transform(X)\n",
        "\n",
        "# ... (rest of your code) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaT-Udw5Ze-1",
        "outputId": "a033e694-52c2-4202-ba6d-1ebf6653896e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['Sample ID']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}